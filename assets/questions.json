[
  {
    "id": 1,
    "c": "Fondamenti",
    "q": "Nowadays, the usage of classical feature extraction and data analysis methods is outdated since the capability of the recent deep learning models and methods made them obsolete and not more present in the common practice",
    "o": [
      "True",
      "False"
    ],
    "a": 1,
    "note": ""
  },
  {
    "id": 2,
    "c": "Fondamenti",
    "q": "Artificial Intelligence can be applied to the following sectors",
    "o": [
      "Robotics",
      "Information Extraction",
      "All the above"
    ],
    "a": 2
  },
  {
    "id": 3,
    "c": "Fondamenti",
    "q": "Artificial neural networks are capable to learn human biases",
    "o": [
      "False: the achievable complexity of the artificial neural networks is so far from the complexity of the human brain to make impossible to mimic this characteristic",
      "False: human biases are not reproducible nor measurable",
      "True"
    ],
    "a": 2
  },
  {
    "id": 4,
    "c": "Fondamenti",
    "q": "Recent artificial intelligence models can solve analogy puzzles",
    "o": [
      "False",
      "True"
    ],
    "a": 1
  },
  {
    "id": 5,
    "c": "Fondamenti",
    "q": "Considering the \"Data knowledge spectrum plot\" discussed in class, the minimum amount of data required is in the following case.",
    "o": [
      "No knowledge about the model generating the data is available",
      "A statistical model of the process is available",
      "A mathematical model of the process is available"
    ],
    "a": 2
  },
  {
    "id": 6,
    "c": "Fondamenti",
    "q": "It is possible to think to the single datum in input to the neural network as a point in the \"input space\" of the model, even if the input is a single value, a N dimensional vector, or an image",
    "o": [
      "True",
      "False"
    ],
    "a": 0
  },
  {
    "id": 7,
    "c": "Fondamenti",
    "q": "It is correct to say the one of the key features of an intelligent artificial system is the capability to learn (even if only a limited sense) and/or get better in time",
    "o": [
      "True",
      "False"
    ],
    "a": 0
  },
  {
    "id": 8,
    "c": "Fondamenti",
    "q": "According to the Andries Engelbrecht definition of Computational intelligence what of the following is not included?",
    "o": [
      "Artificial Neural Networks",
      "Evolutionary Computing",
      "Swarm Intelligence",
      "Artificial immune system",
      "Fuzzy Systems",
      "All the above are included"
    ],
    "a": 5
  },
  {
    "id": 9,
    "c": "Fondamenti",
    "q": "According to the class discussion of the Gestalt capability, what of the following sentences is more correct?",
    "o": [
      "The Gestalt capability is a typical feature present by-design in the model of classical neural networks",
      "The Gestalt capability is a typical feature present by-design in the model of deep learning neural networks",
      "The Gestalt capability is a typical human feature not well (yet) mimicked in current artificial networks"
    ],
    "a": 2
  },
  {
    "id": 10,
    "c": "Dati",
    "q": "The following activity: Data Selection, Data Filtering, Data Enhancing",
    "o": [
      "Are part of the job of the artificial intelligent specialist in normal activities",
      "Contribute to keep lower the complexity of the learning task",
      "All the above",
      "Are part of the classical machine learning approaches and they are (correctly)"
    ],
    "a": 2
  },
  {
    "id": 11,
    "c": "Modelli",
    "q": "The Mean Squared Error is typically present in what step of the design",
    "o": [
      "Representation",
      "Evaluation"
    ],
    "a": 1
  },
  {
    "id": 12,
    "c": "Vision",
    "q": "Considering IoT devices as source of data for external intelligent systems (IS is not intended to be embedded into the loT device), what kind of loT devices can be really used?",
    "o": [
      "Passive data IoT devices",
      "Active data loT devices",
      "Dynamic data loT devices",
      "All of the above",
      "None of the above"
    ],
    "a": 3
  },
  {
    "id": 13,
    "c": "Modelli",
    "q": "Referring to the class discussion, the (correct) design practice for neural networks considers",
    "o": [
      "Start with deep learning models since they are the cutting edge and most advanced technology that we have now",
      "Start with deep learning models since they are the cutting edge and most advanced technology we have now, and then use classicals method as reference",
      "Start with simple neural networks before to consider deep learning models"
    ],
    "a": 2
  },
  {
    "id": 14,
    "c": "Dati",
    "q": "The missing values can also be occupied by computing mean, mode or median of the observed given values.",
    "o": [
      "This is very unusual and not common in practice",
      "This is a very simple and effective solution in case the learning method is not capable to deal with missing data",
      "This is not possible, since that is just descriptive statistics about the features, and cannot be used to fill missing data"
    ],
    "a": 1
  },
  {
    "id": 15,
    "c": "Dati",
    "q": "An additional information can allow the model to learn or know something that it otherwise would not know and in turn invalidate the estimated performance of the model being constructed. This is called",
    "o": [
      "Data leakage",
      "Data pre-processing",
      "Data harmonization",
      "Data wrangling"
    ],
    "a": 0
  },
  {
    "id": 16,
    "c": "Fondamenti",
    "q": "The degrees of freedom for a given problem are the number of independent problem variables which must be specified to uniquely determine a solution. Hence the #DoF is important to be considered",
    "o": [
      "To design the number of vectors in the learning dataset.",
      "To avoid overfitting problem in the model",
      "All the above",
      "None of the above"
    ],
    "a": 2
  },
  {
    "id": 17,
    "c": "Dati",
    "q": "About the cosine metrics it is possible to say that",
    "o": [
      "Two vectors with the same orientation have a cosine similarity of 1",
      "Two vectors oriented at 90° relative to each other have a similarity of 0",
      "All of the above",
      "None of the above"
    ],
    "a": 2
  },
  {
    "id": 18,
    "c": "Dati",
    "q": "What similarity feature/features discussed in class offers/offer the property to allow a fast comparison based on a short 1D vector of elements or bits",
    "o": [
      "phash",
      "ahash",
      "All the above",
      "Cross-correlation"
    ],
    "a": 2
  },
  {
    "id": 19,
    "c": "Dati",
    "q": "In agreement to the class discussion, which description better describes the design activity?",
    "o": [
      "Similarity in the dataset requires more space and processing time",
      "Similarity in the dataset can improve generalization",
      "Both of the above",
      "None of the above"
    ],
    "a": 2
  },
  {
    "id": 20,
    "c": "Dati",
    "q": "In agreement to the class discussion, in a dataset of 1100 labelled images, the search for duplications is typically achieved...",
    "o": [
      "by manual exploration of the dataset for better results since the number of images is not critical",
      "by automatic iterations > 1M comparisons",
      "by automatic iterations > 1000 comparisons"
    ],
    "a": 1
  },
  {
    "id": 21,
    "c": "Dati",
    "q": "In agreement to the class discussion, what kind of labelling error is generally the worst case for the accuracy of the generalization of the model?",
    "o": [
      "ERR1 (Duplications with same labels)",
      "ERR2 (Duplications with different labels)",
      "ERR1 = EER2"
    ],
    "a": 1
  },
  {
    "id": 22,
    "c": "Vision",
    "q": "According to the class discussion, about the relationship between the operation of cross-correlation and convolution it is possible to say that",
    "o": [
      "They are very similar in meaning and mathematical expression",
      "Despite the mathematical expression is similar, the meaning and their use is completely different",
      "There is no specific relationship since they are different in meaning and mathematical expressions"
    ],
    "a": 0
  },
  {
    "id": 23,
    "c": "Vision",
    "q": "According to the class discussion, what is the characteristic of the self-correlation (O=xcor2(A,A)) map produced by a generic image?",
    "o": [
      "A flat and noisy central plateau",
      "An evident spike at the center with a very well-defined maximum",
      "It is not possible to create an autocorrelation map from one single images, two different images are needed"
    ],
    "a": 1
  },
  {
    "id": 24,
    "c": "Dati",
    "q": "If your data set contains extreme outliers, it better to use as preprocessing",
    "o": [
      "Feature clipping",
      "Min-max normalization",
      "Z' norm"
    ],
    "a": 0
  },
  {
    "id": 25,
    "c": "Dati",
    "q": "A logarithmic scaling to one feature values is typically applied in a case of",
    "o": [
      "Outliers' presence",
      "Negative values",
      "A very large range in the values (>0)"
    ],
    "a": 2
  },
  {
    "id": 26,
    "c": "Dati",
    "q": "According to the scientific visualization rules presented in class, if you are plotting many figures of merit obtained by your trained neural network on a new dataset, which is the correct ranking of visual attributes to be used?",
    "o": [
      "Left: low accuracy Right: HIGH ACCURACY",
      "Color intensity > Hue > Length",
      "Area > Length > Hue",
      "Slope > Angle > Volume",
      "Hue > Area > Length"
    ],
    "a": 4
  },
  {
    "id": 27,
    "c": "Dati",
    "q": "According to the discussion presented in class about the data visualization, and considering the following steps of the design workflow 1) Get Data, 2) Clean Manipulate Data, 3) Train models, 4) Test Data, 5) Improve the design, which are the main step/steps where data visualization should be involved?",
    "o": [
      "#5",
      "#1 and #5",
      "#3 and #5",
      "#2 and #5"
    ],
    "a": 3
  },
  {
    "id": 28,
    "c": "Vision",
    "q": "According to the discussion presented in class about the similarity, consider an image A(x,y) with internal similarity (repetitions of patterns). What happens to the output of the self-cross correlation (O=xcorr2(2, 2))",
    "o": [
      "It is not possible to apply the cross correlation to the same image",
      "Output O tends to be a flat plateau with one clear central peak",
      "Output O tends to have many peaks and one evident maximum",
      "Output O tends to have many equivalent peaks with the same maximum value"
    ],
    "a": 2
  },
  {
    "id": 29,
    "c": "Vision",
    "q": "Machine Learning on CPUs offer the following advantages",
    "o": [
      "Ease of portability and use-case flexibility, Market availability at different performance and prices",
      "Ease of portability and use-case flexibility, Market availability at different performance and prices, Deployment across a wide spectrum of devices",
      "Ease of portability and use-case flexibility, Deployment across a wide spectrum of devices",
      "Market availability at different performance and prices, Deployment across a wide spectrum of devices"
    ],
    "a": 1
  },
  {
    "id": 30,
    "c": "Dati",
    "q": "According to the class discussion, text prefiltering is often used as input for a neural network to deal with a large text input making the networks able to classifiy the input",
    "o": [
      "True, using the hamming distance as prefilering",
      "True, using the cosine distance as prefilering",
      "True, using the string approximate match distance as prefilering",
      "True, using the discrete gradient descent as prefilering",
      "True, using the so-called \"word embeddings\" technique"
    ],
    "a": 4
  },
  {
    "id": 31,
    "c": "Modelli",
    "q": "The Inception-v3 deep learning pretrained model discussed during the course is a model for",
    "o": [
      "Post processing",
      "None of the other options",
      "Image Enhancing",
      "Image classification",
      "Segmentation"
    ],
    "a": 3
  },
  {
    "id": 32,
    "c": "Vision",
    "q": "Intelligent vision systems can achieve Semantic segmentation by",
    "o": [
      "A hybrid approach by blob detection to select candidate ROIs and then image classification of the ROIs",
      "A complete fully convolutional solution",
      "A hybrid approach by blob detection to select candidate ROIs and then image segmentation of the ROIs",
      "None of the other options"
    ],
    "a": 1
  },
  {
    "id": 33,
    "c": "Modelli",
    "q": "An Al model is processing an input RGB image to evaluate the age expressed in years of the face present in the image. What kind of model is it?",
    "o": [
      "Classifier Model",
      "Regressor Model",
      "Clustering Model",
      "Reinforced Learning Model",
      "None of the above"
    ],
    "a": 1
  },
  {
    "id": 34,
    "c": "Fondamenti",
    "q": "Acoording to class discussion, the theory of intelligent systems should include the following designing steps:",
    "o": [
      "Representation",
      "Representation, Evaluation",
      "Representation, Evauation, Optimization",
      "None of the other option"
    ],
    "a": 2
  },
  {
    "id": 35,
    "c": "Modelli",
    "q": "Clustering always requires supervised dataset",
    "o": [
      "Yes",
      "No"
    ],
    "a": 1
  },
  {
    "id": 36,
    "c": "Modelli",
    "q": "Acoording to class discussion, using a black box solution is:",
    "o": [
      "Bad practice for a ML designer",
      "Can be used under specific circumstances",
      "Since all state of the art models tend to be quite large and un-explainable, it is current good practice to adopt black box approach since you get the best models"
    ],
    "a": 0
  },
  {
    "id": 37,
    "c": "Dati",
    "q": "You have a dataset X of 1000 samples and number of features F=4 features. You want to reduce the number of features F to 2 for data visualization. According to the goal, consider the following options. OPTION A: Apply PCA to X and select only the first 2 Principal Components. OPTION B: Apply the Feedforward Feature Selection to X and select onlythefirst",
    "o": [
      "is NOT possible",
      "Option A is NOT possible. Option B is possible",
      "Option A is possible. Option B is possible.",
      "Option A is possible. Option B is NOT possible."
    ],
    "a": 2
  },
  {
    "id": 38,
    "c": "Dati",
    "q": "You have a feature in your dataset with the following values F1=[-5, 0, +5], which normalization will give you the following F1_norm =[0, 0.5, 1",
    "o": [
      "Z-score",
      "Clipping",
      "Min-MAX",
      "A different type of normalization"
    ],
    "a": 2
  },
  {
    "id": 39,
    "c": "Modelli",
    "q": "According to the class discussion, in general for a given small dataset X, if you train a feed-forward neural models (of the same type) with an increasing number of neurons, which case is more probable?",
    "o": [
      "None of the below",
      "The training error and the validation will decrease indefinitely",
      "The training error will increase",
      "The validation error will decrease indefinitely"
    ],
    "a": 0
  },
  {
    "id": 40,
    "c": "Modelli",
    "q": "According to the class discussion, in a cross-validation single test, which train/test partition of the samples will provide the lower training error but the lower confidence in the test results?",
    "o": [
      "Training set = 99%, Test Set = 01%",
      "Training set = 75%, Test Set = 25%",
      "Training set = 50%, Test Set = 50%",
      "Training set = 25%, Test Set = 75%",
      "Training set = 01%, Test Set = 99%"
    ],
    "a": 0
  },
  {
    "id": 41,
    "c": "Modelli",
    "q": "According to the class discussion, what kind of activity can be performed on the test set?",
    "o": [
      "All the below",
      "Mean test error estimation",
      "Mean test error estimation and standard deviation",
      "Confusion matrix test"
    ],
    "a": 0
  },
  {
    "id": 42,
    "c": "Modelli",
    "q": "According to the class discussion, what kind of activity can be performed on the train set?",
    "o": [
      "Design of the #of neurons",
      "Design of the #of layers",
      "Normalization",
      "PCA",
      "All the other options"
    ],
    "a": 4
  },
  {
    "id": 43,
    "c": "Modelli",
    "q": "According to the class discussion, where can be performed the feature engineering?",
    "o": [
      "Only on the test set",
      "On the train set and the test set",
      "Not on the train, not on the test set, but only on a different dataset",
      "Only on the train set"
    ],
    "a": 3
  },
  {
    "id": 44,
    "c": "Modelli",
    "q": "Which option is correct?",
    "o": [
      "From the confusion matrix is possible to process the classification error and vice versa",
      "The confusion matrix is applicable only to binary classification systems",
      "From the confusion matrix is possible to process the classification error",
      "The classification error is equal to the sum of the diagonal elements of the confusion matrix"
    ],
    "a": 2
  },
  {
    "id": 45,
    "c": "Modelli",
    "q": "According to the notation used in class, which kind of a model is described by the equation f(x)=sgn(w*x+b)",
    "o": [
      "Liner regressor",
      "Soft-max neuron",
      "Sigmoidal neuron",
      "Liner classifier",
      "Gradient descent formula",
      "Number of the model's parameters"
    ],
    "a": 3
  },
  {
    "id": 46,
    "c": "Modelli",
    "q": "According to the notation used in class, which kind of a classifier is better described by the following definition: \"the output is the label produced by the most probable classifier\"",
    "o": [
      "Supervised Classifier",
      "K-means",
      "Bayes Optimal Classifier",
      "None of the other options"
    ],
    "a": 2
  },
  {
    "id": 47,
    "c": "Modelli",
    "q": "According to the class discussion the kNN classifier, what kind of learning is it?",
    "o": [
      "Instance-based Learning",
      "Eager Learning",
      "Hard-limited Learning",
      "Unsupervised Clustering",
      "None of the other options"
    ],
    "a": 0
  },
  {
    "id": 48,
    "c": "Modelli",
    "q": "According to the class discussion, what is the classifier with the following properties: not based on neural techniques; it's deterministic with no random initialization; perfect repeatability; a minimum number of parameters is needed; learning is very simple but effective; perfect explain ability",
    "o": [
      "Linear classifier",
      "Decision Tree",
      "KNN",
      "K-means",
      "None of the other options"
    ],
    "a": 2
  },
  {
    "id": 49,
    "c": "Modelli",
    "q": "According to the class discussion on KNN classifiers about the k parameter and its relationship to regularization of the decision boundaries and the computational complexity, what is the correct option about larger values of k?",
    "o": [
      "Less regularization and more complexity",
      "More regularization and more complexity",
      "Less regularization and less complexity",
      "More regularization and less complexity",
      "The parameter k is not related to regularization and complexity"
    ],
    "a": 1,
    "note": "NOTA SCIENTIFICA: Nel ML, un K maggiore (media su più vicini) crea confini più lisci (più bias, meno varianza, quindi 'più regolarizzazione') ma riduce la complessità del modello. Il quiz considera 'more complexity' come risposta corretta, forse riferendosi al costo computazionale."
  },
  {
    "id": 50,
    "c": "Dati",
    "q": "According to the class discussion on PCA what is the correct option?",
    "o": [
      "PCA vectors are originating from the center of mass of the points",
      "All subsequent principal component vectors are orthogonal",
      "All the other options"
    ],
    "a": 2
  },
  {
    "id": 51,
    "c": "Dati",
    "q": "According to the class discussion on PCA what is the correct option?",
    "o": [
      "All subsequent principal component vectors are orthogonal",
      "The variance of the data projection on the first PCA vectors is maximized",
      "All the other options"
    ],
    "a": 2
  },
  {
    "id": 52,
    "c": "Modelli",
    "q": "According to the class discussion about unsupervised learning, what is the method with the following properties: you need to specify the number of clusters k in advance, is unable to handle noisy data and outliers, it is not suitable to discover clusters with non-convex shapes",
    "o": [
      "K-means",
      "KNN",
      "Decision tree",
      "None of the other options"
    ],
    "a": 0
  },
  {
    "id": 53,
    "c": "Modelli",
    "q": "According to the class discussion, considering the equation of the backpropagation in a feedforward neural network of weight w_ij connected to the following output neuron k, which is the missing term? DELTAW_ij = ? * y_j * delta_k",
    "o": [
      "?? = x_j (the input vector)",
      "??? = alfa (the regularization term > 1)",
      "??= alfa (the regularization term < 1)",
      "??? = x_j (the input vector error)"
    ],
    "a": 2
  },
  {
    "id": 54,
    "c": "Modelli",
    "q": "According to the class discussion, considering a general CNN architecture, what is the sequence of modules which is more likely",
    "o": [
      "Input layer -> Relu -> Convolution -> Max Pooling -> Softmax -> Output layer",
      "Input layer -> Relu -> Max Pooling -> Softmax -> Convolution -> Output layer ahash",
      "Input layer -> Relu -> Max Pooling -> Convolution -> Softmax -> Output layer",
      "Input layer -> Convolution -> Relu -> Max Pooling -> Softmax -> Output layer"
    ],
    "a": 3
  },
  {
    "id": 55,
    "c": "Vision",
    "q": "According to the class discussion, Traditional Segmentation methods are quite useful to produce blobs or object candidates to be further processed by deep models for classification or measurements. Traditional Segmentation methods can be partitioned in",
    "o": [
      "Global knowledge, Edge-based",
      "Edge-based, Region-based",
      "Global knowledge, Edge-based, Region-based",
      "None of the other options"
    ],
    "a": 2
  },
  {
    "id": 56,
    "c": "Vision",
    "q": "According to the class discussion referred to edge computing, is it possible to process images with trained deep learning models on external small, dedicated devices connect via USB connection?",
    "o": [
      "True: the usage of dedicated processors and the USB bandwidth make this option possible",
      "False: the USB bandwidth make this option not possible",
      "False: the needed computational complexity needed to run trained deep learning models make this option not possible",
      "False: the bandwidth and the computational complexity need to process images with trained deep learning model is not adequate"
    ],
    "a": 0
  },
  {
    "id": 57,
    "c": "Modelli",
    "q": "According to the class discussion what is Greedy Layer-Wise Training?",
    "o": [
      "A supervised training step to improve auto-encoders",
      "A supervised training step to classical feedforward networks",
      "An unsupervised training step to classical feedforward networks",
      "An unsupervised training step to improve auto-encoders"
    ],
    "a": 3
  },
  {
    "id": 58,
    "c": "Modelli",
    "q": "The number of parameters to be fixed during a complete training in a deep learning model like the VGGNet presented in the course is about",
    "o": [
      "< 100000",
      "> 100 Million",
      "about 1 Million",
      "about 10 Million"
    ],
    "a": 1
  },
  {
    "id": 59,
    "c": "Dati",
    "q": "Considering the class discussing about the basic metrics in data similarity, given a vector A, vector B, a real number alpha, and the cosine metrics cos(A,B) it is possible to say that",
    "o": [
      "alpha * cos(A,B) = cos(alpha*A, B)",
      "cos(A,B) = cos(alpha*A, alpha*B)",
      "cos(A,B) = cos(alpha*A, B) = cos(A, alpha*B)",
      "alpha * cos(A,B) = cos(alpha*A, alpha*B)"
    ],
    "a": 0,
    "note": "NOTA SCIENTIFICA: Matematicamente, cos(alpha*A, B) = cos(A, B) se alpha > 0 (la scala non cambia l'angolo). L'equazione corretta nel quiz (alpha * cos = ...) implica che il coseno scali linearmente, il che è tecnicamente errato a meno che non sia una convenzione specifica."
  },
  {
    "id": 60,
    "c": "Dati",
    "q": "Referring to the class discussion on data leakage what is the worst situation?",
    "o": [
      "The unwanted leakage of data from training dataset to test data set",
      "None of the other options since transferring data from test and/or training dataset is normal when the accuracy of the model is tested",
      "The unwanted leakage of data from test dataset to training data set since you are subtracting data to the generalization test, making the situation more pessimistic",
      "The unwanted leakage of data from test dataset to training data set since you are subtracting data to the generalization test, making the situation more optimistic"
    ],
    "a": 3
  },
  {
    "id": 61,
    "c": "Vision",
    "q": "What task of an intelligent vision system is associated to following description: split or separate an image into regions using features, patterns and colors to facilitate recognition, understanding, and Region Of Interests (ROI) processing and measurements.",
    "o": [
      "Model training",
      "Post processing",
      "Enhancing",
      "Segmentation",
      "Feature engineering"
    ],
    "a": 3
  },
  {
    "id": 62,
    "c": "Dati",
    "q": "In agreement to the class discussion, what kind of labelling error is generally the worst case for the accuracy of the generalization of the model?",
    "o": [
      "ERR1 = Duplications with same labels, EER2 = Duplications with different labels",
      "ERR1 is equalt to EER2 by definition",
      "ERR2 is the worst case",
      "ERR1 is the worst case",
      "ERR1 is roughly equalt to EER2 in general"
    ],
    "a": 2
  },
  {
    "id": 63,
    "c": "Vision",
    "q": "According to the class discussion, the convolution/correlation operations are of foundamental relevance for many deep learning models. What is the characteristic of the autocorrelation map produced by a generic image?",
    "o": [
      "It is not possible to create an autocorrelation map from one single images, two different images are needed",
      "None of the other options",
      "A flat and noisy central plateau",
      "An evident spike at the center with a very well defined maximum"
    ],
    "a": 3
  },
  {
    "id": 64,
    "c": "Vision",
    "q": "A tensor processing unit (TPU) is",
    "o": [
      "A part of a model of the Convolutional Neural Network used to process dedicated tensorial activation functions in the neurons",
      "An internal unit of the Arm processor architecture introduced to support 8-bit fixed-point matrix multiplication for deep learning models",
      "An Al accelerator application-specific integrated circuit (ASIC) and the related board developed specifically for neural network machine learning",
      "None of the other options"
    ],
    "a": 2
  },
  {
    "id": 65,
    "c": "Dati",
    "q": "You have a feature in your dataset with the following values F2 = [ -13 0 1 2 4 128], which normalization will give you the following F2_norm = [0 0 1 2 4 10 ]",
    "o": [
      "Z-score",
      "Min-MAX",
      "Clipping",
      "A different type of normalization"
    ],
    "a": 1,
    "note": "NOTA SCIENTIFICA: Se fosse Min-Max lineare, 128 diventerebbe 1 (o 10 se scalato). Qui 128 diventa 10 mentre 4 resta 4. Sembra esserci un clipping o una funzione non lineare, ma il quiz richiede 'Min-MAX'."
  },
  {
    "id": 66,
    "c": "Vision",
    "q": "Considering the possible Intelligent Vision tasks which is the correct option?",
    "o": [
      "Instance Segmentation is less complex than Object Detection",
      "Instance Segmentation is more complex than Object Detection",
      "Instance Segmentation and Object Detection have a similar complexity",
      "The other otpions are not Intelligent Vision tasks"
    ],
    "a": 1
  },
  {
    "id": 67,
    "c": "Vision",
    "q": "In a given picture ImmA you see 1 car and 5 people in a city background. Considering the Intelligent systems IS processing the image ImmA and producing in output the label \"humans\", what Intelligent Vision task is performing?",
    "o": [
      "Inštance segmentation",
      "Object detection",
      "Image classification",
      "Semantic segmentation"
    ],
    "a": 2
  },
  {
    "id": 68,
    "c": "Vision",
    "q": "According to the class discussion, considering the training of deep learning models on standard CPUs and standard commercial GPUs boards, what is the gain in training performance (time) and efficiency (energy) for a medium/large-size project?",
    "o": [
      "About 100x in performance and 10x in efficiency",
      "More than 100x in performance and more than 5x in efficiency",
      "About 10x in performance and 5x in efficiency",
      "About 2x in performance and 2x in efficiency"
    ],
    "a": 2
  },
  {
    "id": 69,
    "c": "Vision",
    "q": "A basic industrial setup for Intelligent vision systems is typically composed by the following elements",
    "o": [
      "Standard industrial smart camera with optics, external processing HW and SW units, illumination system",
      "Standard industrial camera with optics, illumination system",
      "Just a standard industrial camera with optics",
      "Standard industrial camera with optics, processing HW and SW units, illumination system",
      "Standard industrial camera with optics, processing HW and SW units"
    ],
    "a": 3
  },
  {
    "id": 70,
    "c": "Modelli",
    "q": "Acoording to class discussion, the classification item and thei decision boundaries, it is possible in general to optimize during the training/optimization step",
    "o": [
      "The accuracy",
      "The margin",
      "Both"
    ],
    "a": 2
  },
  {
    "id": 71,
    "c": "Fondamenti",
    "q": "Acoording to class discussion about Al regulation in EU, regulation approach is based on:",
    "o": [
      "List of use cases",
      "Risk assessment of the application",
      "Both",
      "None of the above"
    ],
    "a": 2
  },
  {
    "id": 72,
    "c": "Fondamenti",
    "q": "Acoording to the discussion presented in class, the EU regulatory framework for Al is:",
    "o": [
      "Mainly focused on public services",
      "Mainly focused on health-related applications",
      "Mainly focused on data privacy",
      "None of the other options"
    ],
    "a": 3
  },
  {
    "id": 73,
    "c": "Modelli",
    "q": "Which of the following statements describe in a most accurate and complete way the properties of the Mean Absolute Error (MAE) metric?",
    "o": [
      "The lower the MAE, the better the model",
      "MAE is less sensitive to outliers compared to MSE",
      "Range: [0,+inf.]",
      "None of other options (except \"All other options\")",
      "All other options (except \"None of other options\")",
      "MAE is calculated as mean(abs(observeds - predicteds))"
    ],
    "a": 4
  },
  {
    "id": 74,
    "c": "Fondamenti",
    "q": "Which type of Al lacks all of the following: self-awareness, consciousness, emotions, genuine intelligence comparable to humans, and Gestalt understanding?",
    "o": [
      "Large Al models",
      "Reactive Al systems",
      "Artificial General Intelligence models",
      "Narrow Al models",
      "None of other options"
    ],
    "a": 3
  },
  {
    "id": 75,
    "c": "Modelli",
    "q": "What is the correct range for the metric Mean Squared Error (MSE)?",
    "o": [
      "[inf.,+inf.]",
      "[0,1]",
      "[0,+inf.]",
      "[-1,1]",
      "None of other options"
    ],
    "a": 2
  },
  {
    "id": 76,
    "c": "Modelli",
    "q": "What is the primary advantage of stratified k-Fold Cross-Validation (k-FCV) compared to simple k-FCV?",
    "o": [
      "It ensures that all data partitions are of equal size",
      "It reduces computational complexity",
      "It preserves the class distribution across all partitions",
      "It improves the training time for large datasets",
      "It eliminates the need for test partitions"
    ],
    "a": 2
  },
  {
    "id": 77,
    "c": "Modelli",
    "q": "In a 1D linear model with the equation z=w1*x+b, how many data points are required to completely describe the model?",
    "o": [
      "4, because it is required at least the double to make invertible the algebra problem solving the parameter",
      "2, because there are two parameters (w1 and b) to determine",
      "3, because one additional point is needed for generalization",
      "1, because the model is linear",
      "None of other options"
    ],
    "a": 1
  },
  {
    "id": 78,
    "c": "Modelli",
    "q": "In the k-Fold Cross Validation (k-FCV) technique, what does the parameter k represent?",
    "o": [
      "The number of dimensions to be reduced with PCA",
      "The number of eigenvalues in the dataset's covariance matrix",
      "The number of partitions the dataset is divided into",
      "The number of neighbors used in a k-NN classification algorithm",
      "The number of annealing steps in a training method"
    ],
    "a": 2
  },
  {
    "id": 79,
    "c": "Fondamenti",
    "q": "Considering the \"Data knowledge spectrum plot\" discussed in class, which of the following cases is correct when just some parameters of the mathematical model must be tuned/fitted?",
    "o": [
      "When no a priori information is available and a huge quantity of data is required to train the model",
      "When the model of the process generating the data is available and a limited quantity of data is required to fit the parameters",
      "When no a-priori information is available and a limited quantity of data is required to train the model",
      "When the model of the process generating the data is available and a huge quantity of data is required to train the model",
      "None of other options"
    ],
    "a": 1
  },
  {
    "id": 80,
    "c": "Modelli",
    "q": "According to the class discussion, in general for a given small dataset X, if you train a feed-forward neural models (of the same type) with an increasing number of neurons, which case is more probable?",
    "o": [
      "None of the other options",
      "The training error and the validation will decrease indefinitely",
      "The training error will increase",
      "The validation error will decrease indefinitely",
      "The validation error will increase"
    ],
    "a": 4
  },
  {
    "id": 81,
    "c": "Fondamenti",
    "q": "The design of intelligent systems for Industry 4.0 applications should be compliant to the following main design principles.",
    "o": [
      "Interoperability, information transparency, improved technical assistance, Decentralized decisions",
      "Interoperability, information transparency, improved technical assistance, Wireless connectivity",
      "Interoperability, information transparency, improved technical assistance",
      "Interoperability, information transparency, Decentralized decisions",
      "None of other options"
    ],
    "a": 0
  },
  {
    "id": 82,
    "c": "Modelli",
    "q": "What is the correct range for the metric Mean Absolute Error (MAE)?",
    "o": [
      "None of other options",
      "[1,1]",
      "[0,+inf.]",
      "[-inf.,+inf.]",
      "[0,1]"
    ],
    "a": 2
  },
  {
    "id": 83,
    "c": "Vision",
    "q": "According to the class discussion, considering a standard Intelligent vision system, which capability can be processed onboard on a recent smart industrial camera?",
    "o": [
      "Segmentation, Measurement, Classification with trained non-deep models",
      "Segmentation, Measurement, Classification with trained deep models and training of deep models",
      "Segmentation, Measurement",
      "Segmentation, Measurement, Classification with trained deep models",
      "Segmentation, Measurement, Classification"
    ],
    "a": 2
  },
  {
    "id": 84,
    "c": "Modelli",
    "q": "The GoogLeNet deep learning pretrained model discussed during the course is model for",
    "o": [
      "None of the other options",
      "Segmentation",
      "Post processing",
      "Image Enhancing",
      "Image classification"
    ],
    "a": 4
  },
  {
    "id": 85,
    "c": "Modelli",
    "q": "A simple k-Fold Cross Validation procedure may",
    "o": [
      "Get stuck into one the local minima",
      "Prevent overfitting",
      "None of the other options",
      "Lead to disarranging the proportion of examples from each class in the test partition",
      "Making impossible to process the test error"
    ],
    "a": 3
  },
  {
    "id": 86,
    "c": "Modelli",
    "q": "Why is it important to maintain a balanced partition between training and test data?",
    "o": [
      "To make the training and test data identical for consistency",
      "To eliminate the need for validation during training",
      "None of other options",
      "To ensure the model can generalize well and avoid biased performance estimates",
      "To ensure the test data is larger than the training data for accurate error estimation"
    ],
    "a": 3
  },
  {
    "id": 87,
    "c": "Modelli",
    "q": "Do you need to adjust the value of k in the k-Fold Cross Validation (k-FCV) technique?",
    "o": [
      "No, because k is fixed by default to 5 or 10 and does not need adjustment",
      "None of other options",
      "No, because adjusting k does not impact the cross-validation results",
      "Yes, to ensure that the number of folds equals the number of classes in the dataset",
      "Yes, to avoid creating a small test partition poorly populated with examples that may bias performance measures",
      "No, because k must always be equal to the number of features in the dataset"
    ],
    "a": 4
  },
  {
    "id": 88,
    "c": "Modelli",
    "q": "Are there differences in how you evaluate the performance of a regressor compared to a classifier?",
    "o": [
      "No, the evaluation process is identical since both are machine learning models",
      "No, both regressors and classifiers are evaluated using the same metrics like accuracy, precision, and F1-score",
      "Yes, regressors are typically evaluated using metrics like accuracy, precision, recall, and F1-score, while classifiers use metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), or R-squared",
      "Yes, regressors are typically evaluated using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), or R-squared, while classifiers use metrics like accuracy, precision, recall, and F1-score",
      "None of other options"
    ],
    "a": 3
  },
  {
    "id": 89,
    "c": "Modelli",
    "q": "Why is the Leave One Person Out technique important for deep learning models?",
    "o": [
      "Because it allows the model to memorize the data for each person individually, ensuring high accuracy",
      "Because it reduces the size of the training set, making the training process faster",
      "None of other options",
      "Because it focuses on overfitting the model to a single person's data for personalization",
      "Because it ensures the model generalizes well by testing on unseen individuals, reducing bias when working with person-specific data"
    ],
    "a": 4
  },
  {
    "id": 90,
    "c": "Modelli",
    "q": "What happens if the whole data set is used for both training and validating a machine learning model?",
    "o": [
      "The model will always perform better on test data",
      "The training error will always be lower than the test error",
      "The model will generalize well to unseen data",
      "We have no clue about how the model will behave with unseen cases",
      "None of other options"
    ],
    "a": 3
  },
  {
    "id": 91,
    "c": "Dati",
    "q": "What is an example of using the 'Divide et Impera' strategy for handling unbalanced datasets?",
    "o": [
      "Use a single classifier trained on all data without considering class distribution",
      "Assign random labels to rare cases to increase variability and improve the training of the model",
      "Create hierarchical classifiers to divide the classification task into smaller, balanced sub-problems",
      "Duplicate rare cases to match the number of majority class samples",
      "Remove rare cases to simplify the dataset"
    ],
    "a": 2
  },
  {
    "id": 92,
    "c": "Dati",
    "q": "Is dividing a time series dataset into training and test sets a potential problem, and can it be addressed using classical cross-validation techniques like k-FCV?",
    "o": [
      "None of other options",
      "No, it is not a problem because temporal dependencies do not affect model performance",
      "Yes, it is a potential problem because it can lead to data leakage, and classical cross-validation techniques are not always suitable due to temporal dependencies",
      "Yes, it is a potential problem but can be addressed using classical cross-validation techniques like k-FCV",
      "No, it is not a problem as time series data behaves like any other dataset"
    ],
    "a": 2
  },
  {
    "id": 93,
    "c": "Modelli",
    "q": "What is a characteristic of overfitting in a machine learning model?",
    "o": [
      "The model is poorly adjusted to the data",
      "The model suffers from high error both in training and test data",
      "None of other options",
      "The training error and test error are both high",
      "The model offers high precision for known cases but behaves poorly for unseen cases"
    ],
    "a": 4
  },
  {
    "id": 94,
    "c": "Modelli",
    "q": "Which of the following statements describe in a most accurate and complete way the properties of the R-squared metric?",
    "o": [
      "The higher the R-squared, the better the model",
      "None of the other options (except \"All other options\")",
      "Range [0,1]",
      "The properties of variation at the outcome that is explained by the predictor variable",
      "All other options (except \"None of other options\")"
    ],
    "a": 4
  },
  {
    "id": 95,
    "c": "Dati",
    "q": "In agreement to the class discussion, in a dataset of 1100 labelled images, the search for duplications is typically achieved",
    "o": [
      "Using hashing functions to check for duplicates",
      "Manually checking each image to avoid errors",
      "By applying a clustering algorithm on the image features and identifying clusters with identical features",
      "Using an automatic script that resizes all images to 1x1 pixels and then compares them",
      "None of other options"
    ],
    "a": 0
  },
  {
    "id": 96,
    "c": "Modelli",
    "q": "Why is it necessary to aggregate the values from individual folds in the k-Fold Cross Validation (k-FCV) procedure?",
    "o": [
      "To summarize the performance across all folds into a single metric.",
      "To ensure the model achieves the lowest possible error on one of the folds",
      "None of other options",
      "To identify the most important fold for model performance",
      "Aggregation is not necessary; each fold is evaluated independently and dropped is not optimal"
    ],
    "a": 0
  },
  {
    "id": 97,
    "c": "Fondamenti",
    "q": "Which of the following best describes Transduction in the context of machine learning?",
    "o": [
      "Creating a new function based on unseen data",
      "None of other options",
      "Deriving the values of the given function for points of interest",
      "Deriving the values of the unknown function for points of interest from the given data",
      "Deriving the function from the given data"
    ],
    "a": 3
  },
  {
    "id": 98,
    "c": "Modelli",
    "q": "Can you perform design activities like deciding the number of neurons or applying regularization on test data?",
    "o": [
      "Yes, it helps refine the model for deployment",
      "Yes, it ensures the model performs better on unseen data",
      "No, test data must be used only for evaluating generalization error",
      "You can design the model after observing the test results to optimize accuracy"
    ],
    "a": 2
  },
  {
    "id": 99,
    "c": "Dati",
    "q": "Which of the following examples highlights a common issue with unbalanced datasets in real-world applications?",
    "o": [
      "In credit scoring, the dataset is balanced because all customers have an equal chance of returning the loan",
      "None of other options",
      "In medical applications, the dataset is typically balanced because the number of healthy and unhealthy patients is equal",
      "In medical applications, most patients are healthy, while only a small fraction suffers from a certain disease",
      "In credit scoring, most customers default on their loans, leading to an unbalanced dataset"
    ],
    "a": 3
  },
  {
    "id": 100,
    "c": "Modelli",
    "q": "What is a characteristic of underfitting in a machine learning model?",
    "o": [
      "The model offers high precision for known cases but behaves poorly for unseen cases",
      "The model performs very well on training data but poorly on test data",
      "The model suffers from high error both in training and test data",
      "None of other options",
      "The model is too tightly adjusted to the training data"
    ],
    "a": 2
  },
  {
    "id": 101,
    "c": "Modelli",
    "q": "Which metric is calculated as TP / (TP + FN) from the confusion matrix?",
    "o": [
      "Recall (Sensitivity)",
      "Specificity",
      "Precision",
      "None of other options",
      "Accuracy"
    ],
    "a": 0
  },
  {
    "id": 102,
    "c": "Modelli",
    "q": "Which of the following is an example of a supervised learning algorithm?",
    "o": [
      "None of other options",
      "k-means clustering",
      "Principal Component Analysis (PCA)",
      "Apriori algorithm",
      "Linear regression"
    ],
    "a": 4
  },
  {
    "id": 103,
    "c": "Modelli",
    "q": "How many parameters are there in a fully connected feedforward neural network with 10 input neurons, 10 neurons in the hidden layer, and 1 output neuron?",
    "o": [
      "100, including weights and biases",
      "121, including weights and biases",
      "101, including weights and biases",
      "300, including all parameters",
      "10, only considering the input layer connections",
      "More than 300, including all parameters"
    ],
    "a": 1
  },
  {
    "id": 104,
    "c": "Dati",
    "q": "Which practice helps prevent Data Leakage?",
    "o": [
      "Including all available data in the training set",
      "Separating features and target variables correctly and ensuring no test data influences training",
      "None of other options",
      "Using fewer features in the dataset",
      "Increasing the complexity of the model to capture more patterns"
    ],
    "a": 1
  },
  {
    "id": 105,
    "c": "Dati",
    "q": "What is a potential outcome of Data Leakage in a machine learning model?",
    "o": [
      "The model achieves perfect generalization on all datasets",
      "The model performs well on the training data but fails to generalize to unseen data",
      "The model requires additional features to improve performance",
      "The model becomes too simple to capture the data distribution",
      "None of other options"
    ],
    "a": 1
  },
  {
    "id": 106,
    "c": "Modelli",
    "q": "How many parameters are there in a fully connected feedforward neural network with 2 input neurons, 2 neurons in the hidden layer 1 output neuron?",
    "o": [
      "12, assuming biases are not included",
      "8, counting connections but omitting biases",
      "6, including weights and biases",
      "9, including weights and biases",
      "None of other options"
    ],
    "a": 3
  },
  {
    "id": 107,
    "c": "Dati",
    "q": "Which of the following describes a valid approach for handling unbalanced datasets using the \"C \"Change labelling\" strategy?",
    "o": [
      "Train a single classifier on the original labels without adjustments",
      "Use uniform sampling to ensure equal representation of all classes",
      "Group and merge rare cases into broader categories",
      "Duplicate rare cases without modifying labels",
      "Ignore rare cases entirely to focus on the majority class"
    ],
    "a": 2
  },
  {
    "id": 108,
    "c": "Modelli",
    "q": "What is the name of the process where the whole data set is randomly partitioned into two equal subsets (A and B), the model is built with A and validated with B, then reversed with the model built with B and validated with A, and the performance measures are aggregated across 5 repetitions?",
    "o": [
      "None of other options",
      "Leave-One-Out Cross Validation",
      "Bootstrap Aggregation (Bagging)",
      "K-Fold Cross Validation",
      "Monte Carlo Validation (Repeated Random Subsampling Validation)"
    ],
    "a": 4
  },
  {
    "id": 109,
    "c": "Dati",
    "q": "Which of the following scenarios is an example of Data Leakage?",
    "o": [
      "Using cross-validation for model evaluation",
      "None of other options",
      "Including features in the training dataset that are derived from the target variable",
      "Applying feature scaling only to the training data",
      "Using a balanced dataset for training and testing"
    ],
    "a": 2
  },
  {
    "id": 110,
    "c": "Dati",
    "q": "According to the class discussion on data leakage, which is the worst case between Test-to-Training Leakage and Training-to-Test Leakage?",
    "o": [
      "Test-to-Training Leakage",
      "Training-to-Test Leakage",
      "Training-to-Test Leakage and Test-to-Training Leakage have similar but small impact on the generation capability since recent deep learning models...",
      "Training-to-Test Leakage and Test-to-Training Leakage have similar and strong impact on generalization capability"
    ],
    "a": 0
  },
  {
    "id": 111,
    "c": "Modelli",
    "q": "Are many Natural Language Processing (NLP) tasks considered transduction problems?",
    "o": [
      "Because the model converts one string into another",
      "Because the model derives a function from given data",
      "None of the other options",
      "Because the model predicts the output without using any input data",
      "Because the model generates unseen data points from an existing function"
    ],
    "a": 0
  },
  {
    "id": 112,
    "c": "Dati",
    "q": "Which of the following scenarios is an example of Data Leakage?",
    "o": [
      "When additional random information is added to the training dataset",
      "When all features are present in the training dataset but not normalized",
      "None of the other options",
      "When a critical feature required for prediction is not present in the training dataset but is used during testing or real-world application",
      "When the training and test datasets are split properly"
    ],
    "a": 3
  },
  {
    "id": 113,
    "c": "Modelli",
    "q": "Where are the correct predictions and errors located in a confusion Matrix?",
    "o": [
      "Errors are located on the diagonal and correct predictions are in the other cells",
      "Errors located on the borders of the Matrix and the correct predictions are in the inner cells",
      "Errors alternate columns starting with one for each class",
      "Correct predictions are located on the diagonal, and errors are off diagonal",
      "None of other options"
    ],
    "a": 3
  },
  {
    "id": 114,
    "c": "Dati",
    "q": "According to the scientific visualization rules presented in class, is it possible to plot a graphical representation of the confidence level of one single figure of merit (like the accuracy) of your trained model?",
    "o": [
      "Yes, the confidence interval data have different units and meaning but they can be represented in the same plot using different visual attributes like \"slope\" and \"area\"",
      "No, the confidence interval data have the same units and meaning and hence can not be represented in the same plot",
      "Yes, the confidence interval data have the same units and meaning and they can be represented in the same plot"
    ],
    "a": 2
  },
  {
    "id": 115,
    "c": "Modelli",
    "q": "We have a neural network NET1 where the Degrees of Freedom are excessive compared to the available data and NET2 where the Degrees of Freedom are balanced compared to the available data. What is likely to happen?",
    "o": [
      "NET1 will have a higher generalization error compared to NET2 due to overfitting",
      "None of other options",
      "NET1 will generalize better than NET2 due to its higher complexity",
      "NET2 will have a higher generalization error due to underfitting",
      "Both NET1 and NET2 will perform equally well regardless of data availability since there are sufficient Degrees of Freedom"
    ],
    "a": 0
  },
  {
    "id": 116,
    "c": "Modelli",
    "q": "In which applications is the Leave One Person Out Cross Validation technique particularly important?",
    "o": [
      "Image classification tasks with large, balanced datasets",
      "Generale-purpose training of deep learning models on standard benchmarks",
      "Biometrics and medical screening, where the model's ability to generalize the trained behavior to unseen individuals is critical",
      "Speech recognition with datasets containing millions of samples"
    ],
    "a": 2
  },
  {
    "id": 117,
    "c": "Dati",
    "q": "Which of the following is a valid solution for handling unbalanced datasets as discussed in class?",
    "o": [
      "Apply random oversampling without analysing class distributions",
      "Collect more data as possible even without considering feature distributions",
      "Use uniform sampling methods to ensure fairness",
      "Increases the weight of the loss for samples from rare classes",
      "Ignore rare cases completely"
    ],
    "a": 2
  },
  {
    "id": 118,
    "c": "Modelli",
    "q": "What does the term \"Degrees of Freedom\" (DoF) refer to in the context of machine learning models?",
    "o": [
      "The difference between training and test error",
      "The number of independent variables or parameters that must be specified to uniquely determine a solution",
      "None of other options",
      "The number of features in the dataset",
      "The total amount of data used in the training set"
    ],
    "a": 1
  },
  {
    "id": 119,
    "c": "Dati",
    "q": "Considering the class discussing about the basic metrics in data similarity, about the cosine metrics it Is possible to say that",
    "o": [
      "All of the other options",
      "0",
      "Two vectors oriented at 90° relative to each other have a similarity of",
      "The cosine metric is taking into account of the two input vectors just the angular displacement between them",
      "Two vectors with the same orientation have a cosine similarity of 1"
    ],
    "a": 0
  },
  {
    "id": 120,
    "c": "Modelli",
    "q": "Is the Leave One Out (LOO) Cross Validation technique suitable for vary large datasets, small datasets, or neither?",
    "o": [
      "It is equally suitable for both large and small datasets as it does not depend on dataset size",
      "None of the other options",
      "It is more suitable for very large datasets as it reduces computational complexity",
      "It is a learning method and does not depend on the size of the dataset",
      "It is more suitable for small datasets as it is computationally expensive for very large datasets"
    ],
    "a": 4
  },
  {
    "id": 121,
    "c": "Modelli",
    "q": "In the context of a binary neural classifier, where the decision is created by a weighted sum and a thresholding neuron, what does the Receiver Operating Characteristic (ROC) curve represent?",
    "o": [
      "None of other options",
      "The confusion matrix at a specific threshold",
      "A plot of precision against recall for the classifier",
      "The graphical plot of the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings",
      "A single number summarizing the performance of the classifier"
    ],
    "a": 3
  },
  {
    "id": 122,
    "c": "Modelli",
    "q": "What happens when the training data is overly large compared to the test data in a unbalanced partition?",
    "o": [
      "The test error will be zero regardless of the partition size",
      "The model will have perfect generalization to new data",
      "None of other options",
      "The training error will always be lower than the test error",
      "The model may appear to perform well during training but lacks statistical confidence in generalization"
    ],
    "a": 4
  },
  {
    "id": 123,
    "c": "Fondamenti",
    "q": "According to the class discussion about the input space of the intelligent systems, which is correct option?",
    "o": [
      "It is possible to think to the single datum in input to the neural network as a point in the \"input space\" of the model, even if the input is a single value a N dimensional vector, or an image.",
      "It is possible to think to the single datum in unput to the neural network as a set of N points in the \"input space\" of the model",
      "It is not possible to think to the single datum in input to the neural network as a point in the \"input space\" of the model, in the case of a N dimensional vector when N > 2",
      "Only for linear classifiers and linear regressors it is possible to think to the single datum in input to the neural network as a point in the \"input space\" of the model, even if the input is a single value, a N dimensional vector, or an image."
    ],
    "a": 0
  },
  {
    "id": 124,
    "c": "Modelli",
    "q": "What is the correct formula for the Misclassification Rate, where FP is False Positive, FN is False Negative, and N is the total number of samples?",
    "o": [
      "(TP + TN) / N",
      "(FP + TP) / N",
      "None of other options",
      "(FP + FN) / N",
      "(FN + TN) / N"
    ],
    "a": 3
  },
  {
    "id": 125,
    "c": "Modelli",
    "q": "Which of the following algorithms is NOT an example of supervised learning?",
    "o": [
      "Neural network regressor",
      "None of the options",
      "K-means clustering",
      "Linear regression",
      "Neural network classifier"
    ],
    "a": 2
  },
  {
    "id": 126,
    "c": "Modelli",
    "q": "What is the purpose of aggregating test values in the k-Fold Cross Validation (k-FCV) method?",
    "o": [
      "To obtain an overall performance metric by averaging the results across all folds",
      "None of other options",
      "To select the best fold for final training",
      "To identify the fold with the lowest test error and discard the rest",
      "To optimize the number of features used in the model"
    ],
    "a": 0
  },
  {
    "id": 127,
    "c": "Fondamenti",
    "q": "Which reasoning approach best describes algorithms like k-Nearest Neighbors (k-NN), linguistic transformation rules for language translation, and sequence prediction tasks?",
    "o": [
      "None of other options",
      "Transduction",
      "Deduction",
      "Induction"
    ],
    "a": 1
  },
  {
    "id": 128,
    "c": "Fondamenti",
    "q": "How can Natural Language Processing (NLP) models typically be classified in terms of their reasoning approach?",
    "o": [
      "Transduction",
      "None of other options",
      "Deduction",
      "Induction"
    ],
    "a": 0
  },
  {
    "id": 129,
    "c": "Fondamenti",
    "q": "According to the class discussion, nowadays, the usage of classical feature extraction and data analysis methods is outdated since the capability of the recent deep learning models and methods made them obsolete and not more present in the common practice.",
    "o": [
      "True",
      "False. Most part of the job is about prepare, study and validate the data to create efficient datasets, also with classical tools.",
      "False. For this task the Greedy Lazy Feature Extraction task is be used."
    ],
    "a": 1
  },
  {
    "id": 130,
    "c": "Modelli",
    "q": "What is the purpose of using stratified k-Fold Cross Validation (k-FCV)?",
    "o": [
      "To ensure that only minority classes are included in the test partitions to make the test more robust",
      "To maximize the size of the training data by using all samples for training",
      "To randomly shuffle the dataset without regard for class distributions",
      "To place an equal (or near-equal) number of samples of each class in all partitions, maintaining class distributions"
    ],
    "a": 3
  },
  {
    "id": 131,
    "c": "Modelli",
    "q": "Does sample k-Fold Cross Validation (k-FCV) disarrange the portion of examples from each class in the test partition?",
    "o": [
      "Yes, but only when the dataset is perfectly balanced",
      "No, disarranging class proportions is not related to k-FCV",
      "Yes, it may disarrange the class proportions in the test partition",
      "No, k-FCV always preserves the class proportions"
    ],
    "a": 2
  },
  {
    "id": 132,
    "c": "Fondamenti",
    "q": "According to the class discussion, artificial neural networks are not capable to learn human biases",
    "o": [
      "True. This is because of the gestalt capability present in the neural models",
      "True. The achievable complexity of the artificial neural networks is so far from the complexity of the human brain to make impossible to mimic this characteristic",
      "False."
    ],
    "a": 2
  },
  {
    "id": 133,
    "c": "Modelli",
    "q": "In this approach, the dataset is divided into three groups. Each group is used as a test set once, while the other two groups are used for training. What does this approach represent?",
    "o": [
      "A stratification process for data balancing",
      "A Principal Component Analysis (PCA)",
      "A clustering algorithm for partitioning data",
      "A 3-fold Cross Validation (3CV)",
      "A pruning method for selecting data groups"
    ],
    "a": 3
  },
  {
    "id": 134,
    "c": "Modelli",
    "q": "Which of the following methods represents a correct 3-fold Cross Validation (3CV) approach?",
    "o": [
      "The dataset is divided into three groups, each used and a test set once while the other two groups are used for training",
      "None of the other options",
      "The dataset is divided into three groups, with each group used 50% for training and 50% for validation purposes",
      "The dataset is split into three groups, all used simultaneously for both training and testing",
      "The dataset is divided into three groups, but only one group is used for both training and testing, and interated for the remaining cases"
    ],
    "a": 0
  },
  {
    "id": 135,
    "c": "Dati",
    "q": "How can Data Leakage occur in image dataset?",
    "o": [
      "when features like size, noise, or color, which are present but they are unrelated to the task, are used for differentiate classes",
      "when the dataset is split into training and test sets",
      "when augmentation techniques are applied inconsistenly",
      "when images are normalized before training",
      "none of other options"
    ],
    "a": 0
  },
  {
    "id": 136,
    "c": "Modelli",
    "q": "In the k-Fold Cross Validation (k-FCV) technique, is it possible to calculate both mean(errors) and std(errors)?",
    "o": [
      "No, it is only possible to calculate std(errors) but not mean(errors)",
      "No, it is not possible to calculate either mean(errors) or std(errors) in k-FCV since the values of errors are all equal",
      "No, it is only possible to calculate mean(errors) but not std(errors)",
      "yes, it is possible to calculate both mean(errors) and std(errors) accross all folds",
      "No, it is not possible to calculate either mean(errors) or std(errors) in k-FCV since we have only one value of error"
    ],
    "a": 3
  },
  {
    "id": 137,
    "c": "Vision",
    "q": "Can the assessment of a classifier for an image classification system also include the following methods?",
    "o": [
      "Adding a fair amount of noise to the input to see if the class is flipped",
      "None of the other options (except \"All the other options\")",
      "Changing relevant parts of the image where the main subject is present and checking if the output is changed",
      "All other options (except \"None of the other options\")",
      "Checking with the saliency maps if the classifier is taking into account the right pixels in the subject to be classified"
    ],
    "a": 3
  },
  {
    "id": 138,
    "c": "Modelli",
    "q": "According to the rule of thumb about Degrees of Freedom (DoF), what are they related to in a fully connected neural network?",
    "o": [
      "The number of weights in the hidden layers",
      "the number of feature and the number of weights in the hidden layers",
      "the number of features in the dataset",
      "All other options",
      "The amount of vectors in the dataset for training"
    ],
    "a": 0,
    "note": "NOTA SCIENTIFICA: I gradi di libertà (DoF) di una rete neurale includono TUTTI i parametri (pesi + bias). La risposta 'weights in the hidden layers' è una semplificazione del corso o una regola empirica approssimativa."
  }
]